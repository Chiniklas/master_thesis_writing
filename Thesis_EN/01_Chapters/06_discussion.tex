\chapter{Discussion}
In this chapter, we delve into the results of experiments conducted both in simulation and on the real system. The chapter is structured as follows: The first subsection provides a comprehensive introduction to the leaderboard metrics employed. Sections 6.2, 6.3, and 6.4 discuss the three facets of leaderboard analysis, namely simulation, robustness, and real hardware, respectively. The final section wraps up our current findings and hints at directions for future research.

\section{Introduction to leaderboard metrics}
To compare the performances of various controllers developed for the double pendulum testbench, we have established three distinct leaderboards: the simulation leaderboard, the robustness leaderboard, and the real system leaderboard. Each of these leaderboards is further subdivided into two categories based on the pendubot and acrobot setups.

\subsection{Performance Leaderboard in Simulation and Real system}

In our evaluation of controller performance, we employ a set of metrics that go beyond just measuring task success. They delve deeper into the nuances of controller operation. For experiments conducted both in simulation environments and on real hardware, the performance evaluation metrics remain consistent. These measures span from assessing the fundamental success of a swing-up maneuver to understanding the intricate details of energy and torque usage. Below is a detailed breakdown of each metric:

\begin{itemize}
  \item \textbf{Swingup Success} \(c_{\text{success}}\):
  Determines if the end-effector successfully remains above the predefined threshold by the simulation's conclusion.
  
  \item \textbf{Swingup Time} \(c_{\text{time}}\):
  Measures the duration taken for the pendubot or acrobot to achieve and maintain its position above the threshold line. The metric only considers the swingup successful if the end-effector remains above the threshold until the simulation's end.
  
  \item \textbf{Energy} \(c_{\text{energy}}\):
  Quantifies the total mechanical energy expended during the task.
  
  \item \textbf{Max Torque} \(c_{\tau, \text{max}}\):
  Captures the highest torque applied at any point during the task.
  
  \item \textbf{Integrated Torque} \(c_{\tau, \text{integ}}\):
  Represents the cumulative torque applied throughout the task's duration.
  
  \item \textbf{Torque Cost} \(c_{\tau, \text{cost}}\):
  A quadratic metric that weighs the torques used, defined as \(c_{\tau, \text{cost}} = \sum u^TRu\), where \(R = 1\).
  
  \item \textbf{Torque Smoothness} \(c_{\tau, \text{smooth}}\):
  Reflects the variability or fluctuations in the torque signals by measuring their standard deviation.
  
  \item \textbf{Velocity Cost} \(c_{\text{vel, cost}}\):
  A metric assessing the joint velocities achieved, computed as \(c_{\text{vel}} = \dot{q}^T Q \dot{q}\), with \(Q\) being the identity matrix.
\end{itemize}

We utilize the subsequent criteria to determine the cumulative RealAI Score based on the specified formula:
\begin{equation}
\begin{aligned}
S = c_{\text{success}} \Bigg(& w_{\text{time}}\frac{c_{\text{time}}}{n_{\text{time}}} + \\
& w_{\text{energy}}\frac{c_{\text{energy}}}{n_{\text{energy}}} +
w_{\tau, \text{max}}\frac{c_{\tau, \text{max}}}{n_{\tau, \text{max}}} +
w_{\tau, \text{integ}}\frac{c_{\tau, \text{integ}}}{n_{\tau, \text{integ}}} + \\
& w_{\tau, \text{cost}}\frac{c_{\tau, \text{cost}}}{n_{\tau, \text{cost}}} +
w_{\tau, \text{smooth}}\frac{c_{\tau, \text{smooth}}}{n_{\tau, \text{smooth}}} +
w_{\text{vel, cost}}\frac{c_{\text{vel, cost}}}{n_{\text{vel, cost}}} \Bigg)
\end{aligned}
\end{equation}

The weights and normalizations are:
\begin{table}[H]
  \centering
  \begin{tabular}{lcc}
    \hline
    Criteria & Normalization \(\mathit{n}\) & Weight \(\mathit{w}\) \\
    \hline
    Swingup time & 10.0 & 0.2 \\
    Energy & 100.0 & 0.1 \\
    Max. Torque & 6.0 & 0.1 \\
    Integrated Torque & 60.0 & 0.1 \\
    Torque Cost & 360 & 0.1 \\
    Torque Smoothness & 12.0 & 0.2 \\
    Velocity Cost & 1000.0 & 0.2 \\
    \hline
  \end{tabular}
  \caption{Weights and normalizations for performance leaderboards}
  \label{tab:performance}
\end{table}

In the simulation experiments, the pendubot is modeled using a Runge-Kutta 4 integrator with a timestep of \(dt=0.002s\) over a span of \(T=10s\). We initiate the pendubot in a hanging down configuration, represented as \(x_0 = (0, 0, 0, 0)\), and aim to reach the unstable fixed point of the upright configuration, denoted as \(x_g = (\pi, 0, 0, 0)\). The double pendulum is deemed to have achieved its upright position once the end-effector surpasses the threshold line situated at \(h=0.45m\), with the origin being the mounting point.

When it comes to real hardware experiments, there's a torque limit of 0.5 Nm on the passive joint, which serves to offset the motor's friction. The actuators can operate with a control frequency as high as 500Hz, and each experiment lasts for 10 seconds. The pendubot starts from a hanging down position, with the objective being the unstable fixed point in the upright configuration. Successful attainment of the upright position is confirmed when the end-effector crosses the threshold line set at \(h=0.45m\), measured from the mounting point's origin.

\subsection{Simulation Robustness Leaderboard}
In addition to performance metrics, we also consider robustness metrics. As the ultimate goal is to transfer successful models from a simulation environment to real hardware, it's essential to assess the robustness of controllers developed within the simulation. This helps determine the types of perturbations that affect each controller.

\begin{itemize}
    \item \textbf{Model Inaccuracies \(c_{model}\)}: Model parameters determined through system identification are never perfectly accurate. To evaluate potential inaccuracies, we modify each model parameter individually within the simulator, while keeping the controller's parameters unchanged.

    \item \textbf{Velocity Measurement Noise \(c_{vel, noise}\)}: Controller outputs heavily rely on the captured system state. Particularly with the Quasi Direct Drives (QDDs), online velocity measurements can be noisy. It's crucial for successful transferability that a controller can handle this inherent noise. We test controllers with both the presence and absence of a low-pass noise filter.

    \item \textbf{Torque Noise \(c_{\tau,noise}\)}: It's not only the measurements that can exhibit noise. Sometimes the torque output from the controller might deviate from the intended value.

    \item \textbf{Torque Response \(c_{\tau,response}\)}: The torque requested by the controller is dynamic and can vary throughout execution. Due to mechanical limitations, the motor might not always adjust immediately to abrupt torque changes, leading to overshooting or undershooting the desired torque value. We model this with the equation \(\tau = \tau_{t-1} + k_{\text{resp}} (\tau_{\text{des}} - \tau_{t-1})\), where \(\tau_{\text{des}}\) is the desired torque. In this model, a \(k_{\text{resp}}\) value of 1 indicates flawless torque response, while any deviation from 1 indicates imperfect motor responses.

    \item \textbf{Time Delay \(c_{delay}\)}: Operating in a real-world environment inevitably introduces time delays due to communication lag and system reaction times. It's essential to account for these when evaluating controller performance.
\end{itemize}

The above criteria are employed to compute the comprehensive RealAI Score using the given formula:
\begin{equation}
 S = w_{model} c_{model} + 
    w_{vel, noise} c_{vel, noise} +  
    w_{\tau, noise} c_{\tau, noise} +  
    w_{\tau, response} c_{\tau, response} +  
    w_{delay} c_{delay}
\end{equation}

The weights are:
\begin{equation}
 w_{model} = w_{vel, noise} = w_{\tau, noise} = w_{\tau, response} = w_{delay} = 0.2
\end{equation}

\section{Interpretation of simulation leaderboard}
In the table below, the performance leaderboard results for both the pendubot and acrobot in simulation experiments are presented. Three major types of controllers are listed for comparison. The SAC+LQR controller is our design and is based on the model-free reinforcement learning method. MC-PILCO~\cite{amadio2022model}~\cite{Libera2023AthleticIO}, which stands for Monte Carlo Probabilistic Inference for Learning Control, is a model-based reinforcement learning method. It utilizes probabilistic models to predict the system's dynamics and employs Monte Carlo methods to optimize control policies based on these predictions. This method was implemented by a team from the University of Padova using a remote testing system. tvLQR is an extension of the standard Linear Quadratic Regulator (LQR) control design. It is tailored for systems with time-dependent state-space matrices or where the optimal control needs to be dynamic. Representing the optimal control method, it was implemented by a separate team from DFKI RIC.

\begin{table}[H]
  \centering
 \begin{tabular}{lcccccc}
 \hline
 Criteria & \multicolumn{2}{c}{SAC+LQR} & \multicolumn{2}{c}{MC-PILCO} & \multicolumn{2}{c}{tvLQR} \\
 & Pendubot & Acrobot & Pendubot & Acrobot & Pendubot & Acrobot \\
 \hline
 Swingup Success & success & success & success & success & success & success \\
 Swingup time [s] & 0.65 & 2.06 & 1.43 & 1.1 & 4.2 & 3.98 \\
 Energy [J] & 9.4 & 29.24 & 12.67 & 9.81 & 9.06 & 10.92 \\
 Max. Torque [Nm] & 5.0 & 5.0 & 2.4 & 2.82 & 2.82 & 5.0 \\
 Integrated Torque [Nm] & 2.21 & 4.57 & 3.48 & 1.27 & 2.57 & 2.27 \\
 Torque Cost [N²m²] & 8.58 & 12.32 & 7.77 & 2.27 & 2.0 & 2.47 \\
 Torque Smoothness [Nm] & 0.172 & 0.954 & 0.07 & 0.057 & 0.031 & 0.077 \\
 Velocity Cost [m²/s²] & 44.98 & 193.78 & 94.68 & 242.44 & 137.31 & 100.34 \\
 RealAI Score & 0.801 & 0.722 & 0.891 & 0.869 & 0.827 & 0.8 \\
 \hline
 \end{tabular}
 \caption{Performance scores of various controllers for pendubot and acrobot experiments.}
 \label{tab:performance}
\end{table}

All three controllers are successful with both the Pendubot and Acrobot setups.

In the Pendubot setup, the performance of the SAC+LQR controller is commendable, particularly with a swift swing-up time of 0.65s. The energy consumption of the SAC+LQR controller (9.4J) is significantly lower than that of the MC-PILCO controller (12.67J) and is nearly on par with the tvLQR controller (9.06J). Additionally, its overall RealAI score is competitive, closely trailing the scores of MC-PILCO and tvLQR. However, a notable drawback is its torque smoothness; it performs the worst among the three controllers, being 2.46 times that of MC-PILCO and 5.55 times that of tvLQR.

For the Acrobot setup, the SAC+LQR controller loses its edge in both swing-up time and energy consumption. Its deficit in torque smoothness becomes even more pronounced, leading to a considerably lower RealAI score compared to the other two controllers.

In general, the SAC+LQR controller demonstrates competitive performance in simpler tasks, such as the Pendubot, especially excelling in swing-up time. However, when faced with a more complex challenge like the Acrobot, its performance declines. The MC-PILCO consistently delivers the best overall performance across both setups and is notable for its remarkably low maximum torque input and consistent torque smoothness. Conversely, the tvLQR, a non-learning-based method, highlights its effectiveness in both scenarios. While its swing-up time is relatively extended, its energy consumption and torque smoothness are commendably low, leading to a moderate RealAI score.

\section{Interpretation of robust leaderboard}
In comparison, the SAC+LQR controller achieves a moderate overall robustness score among the three controllers. It exhibits a higher resistance to model inaccuracy (71.9\% for pendubot and 76.7\% for acrobot) compared to MC-PILCO (45.2\% for pendubot and 40.5\% for acrobot) and tvLQR (75.2\% for pendubot and 59.0\% for acrobot). While the other two controllers demonstrate a noticeable decline when tackling the more complex acrobot task, the performance of the SAC+LQR remains consistent. Additionally, SAC+LQR offers better resistance against velocity measurement noise compared to MC-PILCO, though the top score in this category is held by tvLQR. Apart from MC-PILCO, the other two controllers display consistent and strong robustness regarding torque noise and torque response.

When considering time delay, tvLQR outperforms both SAC+LQR and MC-PILCO. As previously predicted, time delay is the Achilles heel for RL-based methods, since high latency can disrupt the Markov decision process entirely.

\begin{table}[H]
  \centering
 \begin{tabular}{lcccccc}
 \hline
 Criteria & \multicolumn{2}{c}{SAC+LQR} & \multicolumn{2}{c}{MC-PILCO} & \multicolumn{2}{c}{tvLQR} \\
 & Pendubot & Acrobot & Pendubot & Acrobot & Pendubot & Acrobot \\
 \hline
 Model inaccuracy [\%] & 71.9 & 76.7 & 45.2 & 40.5 & 75.2 & 59.0 \\
 Velocity noise [\%] & 100.0 & 71.4 & 90.5 & 66.7 & 100.0 & 95.2 \\
 Torque noise [\%] & 100.0 & 100.0 & 100.0 & 81.0 & 100.0 & 100.0 \\
 Torque response [\%] & 100.0 & 100.0 & 100.0 & 90.5 & 100.0 & 100.0 \\
 Time delay [\%] & 76.2 & 61.9 & 90.5 & 19.0 & 100.0 & 76.2 \\
 Overall Score & 0.896 & 0.820 & 0.852 & 0.595 & 0.950 & 0.861 \\
 \hline
 \end{tabular}
 \caption{Robustness scores of various controllers for pendubot and acrobot experiments.}
 \label{tab:robustness}
\end{table}

In general, tvLQR achieves the best robustness scores for both pendubot and acrobot setups, followed by SAC+LQR, with MC-PILCO ranking last. While SAC+LQR boasts consistency in robustness across both setups, time delay remains a significant issue, limiting the robustness of RL-based methods.

\section{Interpretation of real system leaderboard}
This section is about explaining the hardware results. [to be filled]

\begin{table}[H]
  \centering
 \begin{tabular}{lcccccc}
 \hline
 Criteria & \multicolumn{2}{c}{SAC+LQR} & \multicolumn{2}{c}{MC-PILCO} & \multicolumn{2}{c}{tvLQR} \\
 & Pendubot & Acrobot & Pendubot & Acrobot & Pendubot & Acrobot \\
 \hline
 Swingup Success & 4/10 & 0/10 & 10/10 & 10/10 & 8/10 & 10/10 \\
 Swingup time [s] & 0.67 & - & 1.37 & 1.55 & 4.12 & 4.03 \\
 Energy [J] & 37.12 & - & 11.66 & 17.95 & 34.02 & 13.75 \\
 Max. Torque [Nm] & 5.0 & - & 4.99 & 5.0 & 5.0 & 2.98 \\
 Integrated Torque [Nm] & 24.87 & - & 3.72 & 5.93 & 19.06 & 5.61 \\
 Torque Cost [N²m²] & 78.7 & - & 8.93 & 11.73 & 51.88 & 3.26 \\
 Torque Smoothness [Nm] & 0.774 & - & 0.54 & 0.671 & 0.643 & 0.108 \\
 Velocity Cost [m²/s²] & 114.04 & - & 84.61 & 118.38 & 242.34 & 109.77 \\
 Best RealAI Score & 0.767 & - & 0.843 & 0.82 & 0.695 & 0.822 \\
 Average RealAI Score & 0.298 & - & 0.839 & 0.817 & 0.547 & 0.821 \\
 \hline
 \end{tabular}
 \caption{Real hardware performance scores of multiple controllers for pendubot and acrobot experiments.}
 \label{tab:performance}
\end{table}



\section{Conclusion and future work}
This section is to talk about things to be done.

\cleardoublepage
